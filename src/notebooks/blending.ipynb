{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from operator import itemgetter\n",
    "from blending import blend\n",
    "from baselines import *\n",
    "from matrix_factorization import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load common datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pickle/train.pickle', 'rb') as file:\n",
    "    train = pickle.load(file)\n",
    "with open('../data/pickle/test.pickle', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train all the models on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_mean = global_mean(train)\n",
    "user_means = compute_user_means(train)\n",
    "item_means = compute_item_means(train)\n",
    "\n",
    "with open(b'../data/pickle/blending/g_mean_train.pickle', 'wb') as f:\n",
    "    pickle.dump(g_mean, f)\n",
    "with open(b'../data/pickle/blending/user_means_train.pickle', 'wb') as f:\n",
    "    pickle.dump(user_means, f)\n",
    "with open(b'../data/pickle/blending/item_means_train.pickle', 'wb') as f:\n",
    "    pickle.dump(item_means, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, user_features_sgd, item_features_sgd = matrix_factorization_sgd(train, test=None, num_features=25,\n",
    "                                                                   lambda_user=0.011, lambda_item=0.25,\n",
    "                                                                   verbose=True, num_epochs=50)\n",
    "with open(b'../data/pickle/blending/sgd_item_train.pickle', 'wb') as f:\n",
    "    pickle.dump(item_features_sgd, f)\n",
    "with open(b'../data/pickle/blending/sgd_user_train.pickle', 'wb') as f:\n",
    "    pickle.dump(user_features_sgd, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning the matrix factorization using ALS...\n"
     ]
    }
   ],
   "source": [
    "_, user_features_als, item_features_als = matrix_factorization_als(train, test=None, num_features=20,\n",
    "                                                                   lambda_user=0.014, lambda_item=0.575,\n",
    "                                                                   stop_criterion=0.00001, verbose=True)\n",
    "with open(b'../data/pickle/blending/als_item_train.pickle', 'wb') as f:\n",
    "    pickle.dump(item_features_als, f)\n",
    "with open(b'../data/pickle/blending/als_user_train.pickle', 'wb') as f:\n",
    "    pickle.dump(user_features_als, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(b'../data/pickle/blending/g_mean_train.pickle', 'rb') as f:\n",
    "    g_mean = pickle.load(f)\n",
    "with open(b'../data/pickle/blending//user_means_train.pickle', 'rb') as f:\n",
    "    user_means = pickle.load(f)\n",
    "with open(b'../data/pickle/blending/item_means_train.pickle', 'rb') as f:\n",
    "    item_means = pickle.load(f)\n",
    "with open(b'../data/pickle/blending/als_item_train.pickle', 'rb') as f:\n",
    "    item_features_als = pickle.load(f)\n",
    "with open(b'../data/pickle/blending/als_user_train.pickle', 'rb') as f:\n",
    "    user_features_als = pickle.load(f)\n",
    "with open(b'../data/pickle/blending/sgd_item_train.pickle', 'rb') as f:\n",
    "    item_features_sgd = pickle.load(f)\n",
    "with open(b'../data/pickle/blending/sgd_user_train.pickle', 'rb') as f:\n",
    "    user_features_sgd = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_item = load_data('../data/films_CF_train_inf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_user = load_data('../data/users_CF_train_inf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute blending coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnz_row, nnz_col = train.nonzero()\n",
    "nnz_train = list(zip(nnz_row, nnz_col))\n",
    "\n",
    "nnz_row, nnz_col = test.nonzero()\n",
    "nnz_test = list(zip(nnz_row, nnz_col))\n",
    "\n",
    "als = np.zeros(shape=train.shape)\n",
    "sgd = np.zeros(shape=train.shape)\n",
    "for i, (item, user) in enumerate(nnz_train):\n",
    "    als[item, user] = user_features_als[:, user].T.dot(item_features_als[:, item])\n",
    "    sgd[item, user] = user_features_sgd[:, user].T.dot(item_features_sgd[:, item])    \n",
    "for i, (item, user) in enumerate(nnz_test):\n",
    "    als[item, user] = user_features_als[:, user].T.dot(item_features_als[:, item])\n",
    "    sgd[item, user] = user_features_sgd[:, user].T.dot(item_features_sgd[:, item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['als', 'cf_item', 'cf_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.02889231,  0.34081636, -0.34453513]),\n",
       " 0.89749167682417741,\n",
       " 0.9780226355600159)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend(methods, 1, nnz_train, nnz_test, train, test, \n",
    "      g_mean, user_means, item_means, sgd, als, cf_item, cf_user, predict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_methods = ['global_mean', 'user_mean', 'item_mean', 'sgd', 'als', 'cf_item', 'cf_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_lists(my_list):\n",
    "    if len(my_list) > 0:\n",
    "        tmp = sub_lists(my_list[1:])\n",
    "        return tmp + [[my_list[0]] + k for k in tmp]\n",
    "    else:\n",
    "        return [my_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for methods in sub_lists(all_methods):\n",
    "    if methods == []:\n",
    "        continue\n",
    "    w, tr, te = blend(methods, 1, nnz_train, nnz_test, train, test, \n",
    "                g_mean, user_means, item_means, sgd, als, cf_item, cf_user, predict=False)\n",
    "    l.append([tr, te, methods, w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = sorted(l, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_methods = ll[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['als']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_methods[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
