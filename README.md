# Machine Learning Project Recommender System

[Link](https://github.com/armand33/recommender_system/blob/master/report.pdf) to the report for more details.

Authors:
* Armand Boschin
* Guirec Maloisel
* Adrian Valente

### Usage

Make sure you have `data_train.csv` and `sample_submission.csv` in data before all.

To reproduce the results from the final submission, run the `run.py` python script.
It blends the predictions generated by the ALS model (for more details see the report).
The ALS model is pre trained to improve the speed of prediction. The predictions time is :
- with pre trained model : ~ 1 minute
- without the pre trained model : ~ 25 minutes

The pre-trained files are:
- `data/predictions/als_prediction.csv` (that is the prediction generated by the ALS model only)
- `data/pickle/data_train_als.pickle` (that is the approximation of the training set after ALS factorization, that
is the product of the two smaller matrices obtained by ALS)

The final prediction can be found in `data/predictions/blended_prediction.csv`.

### Final model:
The final model is an ALS factorization matrix with tuned parameters and the predictions are dilated by a blending
with ALS as a sole model. The RMSE achieved is 0.97700.

### Requirements:
The code was developed and run under Python 3.6.2. Libraries required are Numpy, Scipy, pickle. Jupyter is also useful in order to go through the development notebooks.

### Organization of the folder:
* **src** : source code
    * run.py : python script that creates the best prediction we have achieved.
    * baselines.py : functions for general_mean, user_means and item_means baselines.
    * cross_validation.py : implementation of cross_validation methods in the case of a recommender system.
    * helpers.py, plots.py : files provided in the lab10
    * utils.py : useful functions to read files, write predictions to file, initialize matrix factorization methods, 
    and compute prediction error.
    * matrix_factorization.py functions to perform ALS and SGD matrix factorization
    * blending.py : functions to perform the blending of various models`
    * notebooks : iPython Notebooks used for testing and development
        - demos.ipynb : testing and predicting with the baselines and ALS and SGD
        - cross_validation_*: cross-validation of the SGD and ALS
        - collaborativeFiltering : training and prediction with the collaborative filtering model. Notebooks useful to 
        generate the files in `data/collaborative_filtering`
* **doc** : documentation
    * project guidelines
    * subject
    * papers used during the project
* **data** : 
    * *pickle* : pickle files used for storing variables (useful with Amazon Web service)
    * *predictions* : folder containing the predictions for each model (here only ALS is provided) They can be generated 
    by running the notebook `demos.ipynb.
    * *collaborative_filtering* : files useful for the collaborative filtering model. As it is really long to train, 
    some files are provided. Generated using the collaborativeFiltering notebooks.
* **report.pdf** : report of the project

